<html><head><meta charset="utf-8"><script src="https://cdn.jsdelivr.net/npm/chart.js@2.8.0"></script>
 <link rel="stylesheet"
       href="http://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/styles/default.min.css">
 <script src="http://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.17.1/build/highlight.min.js"></script>
 <script>hljs.initHighlightingOnLoad();</script>
 <link href="../css/all.css" rel="stylesheet">
<link rel="stylesheet" href="../mystyle.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pretty-checkbox@3.0/dist/pretty-checkbox.min.css">
</head>
<body>
 <ul class="publist-inline" style="text-align:left;"><li class="web"><a href="../index.html">< Index</a></ul><h1 class="title">The Visual Microphone: Passive Recovery of Sound from Video <i class="fas fa-circle graphcol1" style="font-size:150%;color:#43a2ca;"></i> <i class="fas fa-square graphcol5"  style="font-size:150%;color:#1b9e77;"></i> <i class="fas fa-square graphcol6"  style="font-size:150%;color:#7570b3;"></i></h1><ul class="authors">
<li> Abe <span class="family">Davis</span></li>
<li> Michael <span class="family">Rubinstein</span></li>
<li> Neal <span class="family">Wadhwa</span></li>
<li> Gautham J. <span class="family">Mysore</span></li>
<li> Fr√©do <span class="family">Durand</span></li>
<li> William T. <span class="family">Freeman</span></li>
</ul>
<center> SIGGRAPH 2014</center><ul class="publist-inline">
<li class="web"> <i class="fas fa-globe-americas"></i> <a href="https://doi.org/10.1145/2601097.2601119">ACM</a></li>
<li class="pdf"> <i class="far fa-file-pdf"></i> <a href="http://people.csail.mit.edu/mrub/papers/VisualMic_SIGGRAPH2014.pdf">preprint</a></li>
<li class="web"> <i class="fas fa-globe-americas"></i> <a href="http://people.csail.mit.edu/mrub/VisualMic/">Project page</a></li>
<li class="web"> <i class="far fa-file-alt"></i> <a href="http://people.csail.mit.edu/abedavis/research/VisMic/VMSlim.zip">Code</a></li>
<li class="web"> <i class="fas fa-database"></i> <a href="10.1145-2601097.2601119-metadata.json">DOI Metadata</a></li>
</ul>
<center><img width="300" src="10.1145-2601097.2601119-thumb.png"></img></center>
    <hr>
    <div class="row">
    <div class="column2 chart-container" style="position: relative; height:40vh; width:30vw">
    <canvas width="300" height="250" id="myChart" class="chartjs-render-monitor"></canvas>
    </div>
    <div class="column2"><h2>Informations</h2>
    <ul><li><span class="family">Paper topic</span>: Image</li>
<li><span class="family">Nature of the artefact</span>: Code</li>
<li><span class="family">Able to run a replicability test</span>: Yes</li>
<li><span class="family">Replicability score</span>: 3</li>
<li><span class="family">License</span>: unspecified</li>
<li><span class="family">Build mechanism</span>: Not applicable (python, Matlab..)</li>
<li><span class="family">Mandatory dependencies</span>:Paywall Closed source software or libraries</li>
<li><span class="family">Documentation score</span> {0,1,2}: 1</li>
<li><span class="family">Google Scholar Citation</span> (19/01/2020):   200</li>
<li><span class="family">Reviewer</span>: 2</li>
</ul><h2>Comments</h2><pre>The code partially implements the paper, as there is no support for low-framerate videos by exploiting rolling shutter.
For the remaining high fps videos, some of them did not work at all as they resulted in errors (randomly either "Unable to read the file." or "Dot indexing is not supported for variables of this type (l. 275 of VideoReader/read)) which I could not debug, perhaps due to some codec issue. This was the case of Chips2-2200Hz-Mary_MIDI-input.avi,Chips1-2200Hz-Mary_Had-input.avi and Plant-2200Hz-Mary_MIDI-input.avi).
I successfully ran the code on Chips1-20000Hz-Mary_Had-input.avi. The script (which loads a file 'crabchipsRamp.avi' which I did not find) needs to be adapted so that dsamplefactor = 1 instead of 0.1, otherwise the result is almost pure noise, and of course samplingrate = 20000. **Beware** as well that the default nscales = 1 while the paper's results were produced with nscales = 4 (page 4 in the paper), although I didn't hear much difference in the result.
With these settings, I managed to recover a sound in about 1.5 hours on a good laptop, but the sound is much noisier (though still impressive!) than the result shown in the accompanying webpage. The resulting spectrogram can be found here: https://pasteboard.co/ILOq404.png
and the corresponding sound here: https://voca.ro/3qdSKf1zGkX
The webpage states that the output were further processed with "speech enhancement audio denoising" (the paper indicates [Loizou 2005]), though I could not find code for that algorithm.
Since matlab R2015, wavwrite has been replaced by audiowrite.</pre>
    </div>
    </div>
        <script>

          var ctx = document.getElementById('myChart');
          var myChart = new Chart(ctx, {
              type: 'radar',
              data: {
    labels: ['Dependencies', 'Build / Configure', 'Fixing bugs', 'Easy to adapt', 'Can replicate paper results'],
                     datasets: [{
                      label: 'Build/Run Experience (the higher, the better,  {1..5}, 0=N/A )',
                      backgroundColor: 'rgba(54, 162, 235, 0.3)',
                      borderColor: 'rgb(54, 162, 235)',
                      data: [5,5,1,5,3]
                  }]
              },
              options: {
  scale: {
      ticks: {
          suggestedMin: 0,
          suggestedMax: 5,
          stepSize: 1
      }
  }
}
          });


        </script>
    <br><br>
<br><br><ul class="publist-inline" style="text-align:left;font-size:110%"><li > <i ></i> <a href="replicability.json">Download complete data for this entry</a></li></ul></code></pre></body></html>